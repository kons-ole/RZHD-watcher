{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c6c312-d75c-425f-858d-60c972507cf6",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3966ae2-0eff-45cd-bc32-6013fb40d60b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:15.905299Z",
     "iopub.status.busy": "2023-11-12T07:16:15.904614Z",
     "iopub.status.idle": "2023-11-12T07:16:15.927283Z",
     "shell.execute_reply": "2023-11-12T07:16:15.926567Z",
     "shell.execute_reply.started": "2023-11-12T07:16:15.905265Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6aa5c32-7b94-4a82-a457-e3d7f90f7a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:16.011809Z",
     "iopub.status.busy": "2023-11-12T07:16:16.011051Z",
     "iopub.status.idle": "2023-11-12T07:16:20.112167Z",
     "shell.execute_reply": "2023-11-12T07:16:20.111443Z",
     "shell.execute_reply.started": "2023-11-12T07:16:16.011766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 07:16:18.326036: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-12 07:16:18.373898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 07:16:19.156295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.video import r3d_18\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, Normalize, ToTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from tqdm import tqdm\n",
    "import kornia as K\n",
    "import kornia.augmentation as KAug\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927b4907-298c-4c51-bc20-3a5f13dcbe36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.113949Z",
     "iopub.status.busy": "2023-11-12T07:16:20.113202Z",
     "iopub.status.idle": "2023-11-12T07:16:20.122075Z",
     "shell.execute_reply": "2023-11-12T07:16:20.121421Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.113919Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21503c19-e9fe-44cc-b466-2bb441f03f7a",
   "metadata": {},
   "source": [
    "## Создание классов из обучаемых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e1c27b-40c7-464a-accb-9dee1f8cfdc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.123870Z",
     "iopub.status.busy": "2023-11-12T07:16:20.123358Z",
     "iopub.status.idle": "2023-11-12T07:16:20.142828Z",
     "shell.execute_reply": "2023-11-12T07:16:20.142038Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.123848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загрузка данных из CSV-файла\n",
    "csv_data = pd.read_csv('classes.csv')\n",
    "\n",
    "# Создание словаря для сопоставления названия класса и индекса класса\n",
    "class_name_to_idx = pd.Series(csv_data.class_idx.values, index=csv_data.class_name).to_dict()\n",
    "\n",
    "# Предположим, что ваши видеофайлы находятся в папке 'videos'\n",
    "videos_path = Path('./dataset/videos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2645af59-d1e6-4c75-99bb-91a656267598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.144775Z",
     "iopub.status.busy": "2023-11-12T07:16:20.144245Z",
     "iopub.status.idle": "2023-11-12T07:16:20.166521Z",
     "shell.execute_reply": "2023-11-12T07:16:20.165712Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.144748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Генерируем список путей к файлам и соответствующих меток классов\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "for class_name, class_idx in class_name_to_idx.items():\n",
    "    class_path = videos_path / class_name\n",
    "    for video_file in class_path.iterdir():\n",
    "        file_paths.append(str(video_file))\n",
    "        labels.append(class_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95a36a-7607-4c4a-80ca-37b34a09587b",
   "metadata": {},
   "source": [
    "## Нахождение и настройка весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ec48a3-cf39-4ad3-836e-fcd44b1edd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.167967Z",
     "iopub.status.busy": "2023-11-12T07:16:20.167359Z",
     "iopub.status.idle": "2023-11-12T07:16:20.177135Z",
     "shell.execute_reply": "2023-11-12T07:16:20.176530Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.167936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#функция для извлечения кадров из видео\n",
    "def extract_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a38072-c8f4-4cc7-807e-aa67c6a23ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.178587Z",
     "iopub.status.busy": "2023-11-12T07:16:20.177968Z",
     "iopub.status.idle": "2023-11-12T07:16:20.193103Z",
     "shell.execute_reply": "2023-11-12T07:16:20.192418Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.178556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Вычисление средних значений и стандартных отклонений\n",
    "def compute_mean_std(videos_path):\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    n_frames = 0\n",
    "\n",
    "    for video_path in tqdm(videos_path):\n",
    "        frames = extract_frames(video_path)\n",
    "        for frame in frames:\n",
    "            mean += frame.mean(axis=(0, 1))\n",
    "            std += frame.std(axis=(0, 1))\n",
    "            n_frames += 1\n",
    "\n",
    "    mean /= n_frames\n",
    "    std /= n_frames\n",
    "    return mean / 255, std / 255  # Нормализация значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a029073-0751-43ef-8dde-1d197ae83261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.194459Z",
     "iopub.status.busy": "2023-11-12T07:16:20.193955Z",
     "iopub.status.idle": "2023-11-12T07:16:20.207135Z",
     "shell.execute_reply": "2023-11-12T07:16:20.206368Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.194436Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean, std = compute_mean_std(file_paths)\n",
    "# print(f'Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2936dae-8584-42ba-82b5-091b00bc7a5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.209819Z",
     "iopub.status.busy": "2023-11-12T07:16:20.209261Z",
     "iopub.status.idle": "2023-11-12T07:16:20.228025Z",
     "shell.execute_reply": "2023-11-12T07:16:20.227213Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.209791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Определите параметры\n",
    "num_classes = 24  # Замените на количество классов в вашем датасете\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "frame_count = 3  # Количество кадров в каждом видеосемпле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9adeab-82a5-4e50-991a-14b8a349f435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.230134Z",
     "iopub.status.busy": "2023-11-12T07:16:20.229574Z",
     "iopub.status.idle": "2023-11-12T07:16:20.242510Z",
     "shell.execute_reply": "2023-11-12T07:16:20.241732Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.230111Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Трансформации для предобработки видеофреймов\n",
    "transform = Compose([\n",
    "    Resize([128, 171], antialias=True),\n",
    "    CenterCrop([112, 112]),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.3545011, 0.4070217, 0.416456], std=[0.20798995, 0.21007156, 0.21544088])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2de0307-5cd0-457c-bba9-619d53073960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.244060Z",
     "iopub.status.busy": "2023-11-12T07:16:20.243484Z",
     "iopub.status.idle": "2023-11-12T07:16:20.256511Z",
     "shell.execute_reply": "2023-11-12T07:16:20.255736Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.244031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmentation = KAug.AugmentationSequential(\n",
    "    KAug.RandomHorizontalFlip(p=0.5),\n",
    "    KAug.RandomRotation(degrees=10),\n",
    "    data_keys=['input']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706d30a-d2be-49ca-9dca-6b1159ee2ae7",
   "metadata": {},
   "source": [
    "## Обработка видеофайлов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa38784-483a-48a8-854e-186d4b87989d",
   "metadata": {},
   "source": [
    "### Класс создания датасета из видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbdfb9ea-1909-4b0d-a80c-2c5b15ecfb68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.258028Z",
     "iopub.status.busy": "2023-11-12T07:16:20.257490Z",
     "iopub.status.idle": "2023-11-12T07:16:20.270720Z",
     "shell.execute_reply": "2023-11-12T07:16:20.270002Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.258005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None, augmentation=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_count = 3\n",
    "        video_path = self.file_paths[idx]\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        try:\n",
    "            while len(frames) < frame_count:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = Image.fromarray(frame)\n",
    "\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "\n",
    "                frames.append(frame)\n",
    "        finally:\n",
    "            cap.release()\n",
    "\n",
    "        # Применяем аугментацию к каждому кадру в последовательности\n",
    "        if self.augmentation:\n",
    "            seed = torch.randint(0, 1000000, (1,)).item()  # Генерируем случайное число для сидирования\n",
    "            torch.manual_seed(seed)  # Устанавливаем сид для аугментации\n",
    "            frames = [self.augmentation(f) for f in frames]\n",
    "\n",
    "        frames = frames[:frame_count] + [frames[-1]] * (frame_count - len(frames))\n",
    "        frames = torch.stack(frames)\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        return frames, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddb62d-a6c4-440b-9352-c13ed2ca45f1",
   "metadata": {},
   "source": [
    "### Разделение на обучающий и валидационный датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf0c5ac-edf0-4aa7-99e6-b9a0cdc5781f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.272188Z",
     "iopub.status.busy": "2023-11-12T07:16:20.271631Z",
     "iopub.status.idle": "2023-11-12T07:16:20.286119Z",
     "shell.execute_reply": "2023-11-12T07:16:20.285392Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.272159Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Разделение на обучающий и валидационный датасеты\n",
    "train_paths, valid_paths, train_labels, valid_labels = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Создание экземпляров датасета\n",
    "train_dataset = VideoDataset(train_paths, train_labels, transform=transform, augmentation=augmentation)\n",
    "valid_dataset = VideoDataset(valid_paths, valid_labels, transform=transform, augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f154053-662c-4a1d-a7e5-c839081799eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.287490Z",
     "iopub.status.busy": "2023-11-12T07:16:20.287004Z",
     "iopub.status.idle": "2023-11-12T07:16:20.299734Z",
     "shell.execute_reply": "2023-11-12T07:16:20.299036Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.287467Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создание DataLoader'ов\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93eb903-fb7c-46c5-9429-bd4c186728d6",
   "metadata": {},
   "source": [
    "## Создание модели и обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264e674-b79e-4958-8700-68efa1702a71",
   "metadata": {},
   "source": [
    "### Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c9d4dca-84c7-488f-adf6-78c971ab7e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:20.301334Z",
     "iopub.status.busy": "2023-11-12T07:16:20.300717Z",
     "iopub.status.idle": "2023-11-12T07:16:24.645226Z",
     "shell.execute_reply": "2023-11-12T07:16:24.644379Z",
     "shell.execute_reply.started": "2023-11-12T07:16:20.301291Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/r3d_18-b3b3357e.pth\" to /tmp/xdg_cache/torch/hub/checkpoints/r3d_18-b3b3357e.pth\n",
      "100%|██████████| 127M/127M [00:02<00:00, 54.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Создание модели\n",
    "# model = r3d_18(pretrained=True)\n",
    "model = r3d_18(weights=R3D_18_Weights.KINETICS400_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "\n",
    "# Перенесите модель на GPU, если доступно\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Функция потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11add997-7b44-4d4d-9f6a-db548434042d",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f12630-68f6-41f7-a252-f009ed735717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:24.646956Z",
     "iopub.status.busy": "2023-11-12T07:16:24.646329Z",
     "iopub.status.idle": "2023-11-12T07:16:24.680945Z",
     "shell.execute_reply": "2023-11-12T07:16:24.680280Z",
     "shell.execute_reply.started": "2023-11-12T07:16:24.646932Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "writer = SummaryWriter('runs/experiment_name')\n",
    "\n",
    "best_accuracy = 0.0  # Инициализация переменной для лучшей точности\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (videos, labels) in enumerate(train_loader):\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Обнуляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        videos = videos.squeeze(2)\n",
    "        # Прямой проход\n",
    "        outputs = model(videos)\n",
    "        \n",
    "        # Расчет потерь\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Обратное распространение\n",
    "        loss.backward()\n",
    "        \n",
    "        # Оптимизация\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Валидация модели\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for videos, labels in valid_loader:\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "        videos = videos.squeeze(2)\n",
    "        outputs = model(videos)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (100 * correct / total) > best_accuracy:\n",
    "            best_accuracy = 100 * correct / total\n",
    "            torch.save(model.state_dict(), f'model_epoch_kornia_{epoch+1}.pth')\n",
    "            print(f'Model saved at epoch {epoch+1}')\n",
    "        \n",
    "        # Для записи потерь обучения\n",
    "    writer.add_scalar('Training Loss', loss.item(), epoch)\n",
    "\n",
    "    # Для записи точности валидации\n",
    "    writer.add_scalar('Validation Accuracy', 100 * correct / total, epoch)\n",
    "\n",
    "    # Выводим статистику после каждой эпохи\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss.item():.4f}, Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b26fb570-1fe7-48fb-b41c-94479137cbca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:24.682701Z",
     "iopub.status.busy": "2023-11-12T07:16:24.681918Z",
     "iopub.status.idle": "2023-11-12T07:16:25.557378Z",
     "shell.execute_reply": "2023-11-12T07:16:25.556613Z",
     "shell.execute_reply.started": "2023-11-12T07:16:24.682666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), 'action_recognition_kornia_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64d9e6-6629-47ad-9d35-6c967e85fa17",
   "metadata": {},
   "source": [
    "## Проверка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22e160fe-c212-48d0-a421-37592081ea20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:25.558942Z",
     "iopub.status.busy": "2023-11-12T07:16:25.558267Z",
     "iopub.status.idle": "2023-11-12T07:16:26.057211Z",
     "shell.execute_reply": "2023-11-12T07:16:26.056491Z",
     "shell.execute_reply.started": "2023-11-12T07:16:25.558901Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoResNet(\n",
       "  (stem): BasicStem(\n",
       "    (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = r3d_18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load('action_recognition_model.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeedc22c-6600-4d21-9928-d836c3d490bd",
   "metadata": {},
   "source": [
    "### Функции для распознавания действий в видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d011f15a-01fe-49a5-a1f6-aeb2a8c753cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:26.058753Z",
     "iopub.status.busy": "2023-11-12T07:16:26.058127Z",
     "iopub.status.idle": "2023-11-12T07:16:26.069734Z",
     "shell.execute_reply": "2023-11-12T07:16:26.068887Z",
     "shell.execute_reply.started": "2023-11-12T07:16:26.058721Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def display_image(image):\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')  # Отключить оси координат для чистого отображения\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eda5c8c0-7f75-4c87-861a-ca510949d10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:26.071663Z",
     "iopub.status.busy": "2023-11-12T07:16:26.070992Z",
     "iopub.status.idle": "2023-11-12T07:16:26.083610Z",
     "shell.execute_reply": "2023-11-12T07:16:26.082955Z",
     "shell.execute_reply.started": "2023-11-12T07:16:26.071635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_frame(frame, model, transform, device, class_name_to_idx, frame_number, fps):\n",
    "    # Обработка одного кадра в секунду\n",
    "    if frame_number % int(fps) == 0:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(frame)\n",
    "        frame = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(frame)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            class_name = [name for name, idx in class_name_to_idx.items() if idx == predicted.item()][0]\n",
    "            timestamp = frame_number / fps\n",
    "            \n",
    "            return class_name, timestamp\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d17ef09f-e1ff-448e-a254-1b867d0e667e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:26.085029Z",
     "iopub.status.busy": "2023-11-12T07:16:26.084434Z",
     "iopub.status.idle": "2023-11-12T07:16:26.107312Z",
     "shell.execute_reply": "2023-11-12T07:16:26.106676Z",
     "shell.execute_reply.started": "2023-11-12T07:16:26.085000Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def process_frame_group(frame_group, model, transform, device, class_name_to_idx, timestamp, fps):\n",
    "    processed_frames = []\n",
    "    for frame in frame_group:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(frame)\n",
    "        frame = transform(frame)\n",
    "        processed_frames.append(frame)\n",
    "\n",
    "    # Стекирование кадров и добавление батч-размерности\n",
    "    frames_tensor = torch.stack(processed_frames).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(frames_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        class_name = [name for name, idx in class_name_to_idx.items() if idx == predicted.item()][0]\n",
    "    \n",
    "    del frames_tensor\n",
    "    gc.collect()\n",
    "    \n",
    "    return class_name, timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85d730c8-a3df-4cf3-957d-a338cabb8869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:16:26.108842Z",
     "iopub.status.busy": "2023-11-12T07:16:26.108168Z",
     "iopub.status.idle": "2023-11-12T07:16:26.120526Z",
     "shell.execute_reply": "2023-11-12T07:16:26.119881Z",
     "shell.execute_reply.started": "2023-11-12T07:16:26.108812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def process_video_parallel(video_path, model, transform, device, class_name_to_idx):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    action_timestamps = {class_name: [] for class_name in class_name_to_idx.keys()}\n",
    "    \n",
    "    max_workers = 4  # Ограничение количества одновременных задач\n",
    "    \n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    # Выборка трех кадров каждую секунду\n",
    "    frames_to_process = [frames[i:i+3] for i in range(0, len(frames), int(fps)) if i+3 <= len(frames)]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_frame = {executor.submit(process_frame_group, frame_group, model, transform, device, class_name_to_idx, idx / fps, fps): idx for idx, frame_group in enumerate(frames_to_process)}\n",
    "        for future in concurrent.futures.as_completed(future_to_frame):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                class_name, timestamp = result\n",
    "                print(result)\n",
    "                display_image(frames_to_process[future_to_frame[future]][0])\n",
    "                action_timestamps[class_name].append(timestamp)\n",
    "\n",
    "    return action_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "973002cd-21c5-41c3-89fe-90a0709d66f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:28:17.388388Z",
     "iopub.status.busy": "2023-11-12T07:28:17.387399Z",
     "iopub.status.idle": "2023-11-12T07:28:17.824221Z",
     "shell.execute_reply": "2023-11-12T07:28:17.823056Z",
     "shell.execute_reply.started": "2023-11-12T07:28:17.388348Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "range() arg 3 must not be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4b43425572d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zx,c.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Убедитесь, что модель находится в режиме .eval() и загружена на устройство перед вызовом этой функции\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtimestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_video_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f9ac818651de>\u001b[0m in \u001b[0;36mprocess_video_parallel\u001b[0;34m(video_path, model, transform, device, class_name_to_idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Выборка трех кадров каждую секунду\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mframes_to_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfuture_to_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_frame_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_to_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: range() arg 3 must not be zero"
     ]
    }
   ],
   "source": [
    "video_path = 'zx,c.mp4'\n",
    "# Убедитесь, что модель находится в режиме .eval() и загружена на устройство перед вызовом этой функции\n",
    "timestamps = process_video_parallel(video_path, model, transform, device, class_name_to_idx)\n",
    "\n",
    "for action, times in timestamps.items():\n",
    "    print(f\"Действие '{action}' обнаружено в следующих временных метках: {times}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880eaf3-9bea-4857-85d7-3f752ec02801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
